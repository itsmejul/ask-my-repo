{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96836300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Loads env from .env file\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"Missing GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecabbc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgroq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Groq\n\u001b[32m      2\u001b[39m client = Groq(api_key=\u001b[33m\"\u001b[39m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m completion = client.chat.completions.create(\n\u001b[32m      4\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mllama-3.3-70b-versatile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     messages=[\n\u001b[32m      6\u001b[39m         {\n\u001b[32m      7\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mExplain why fast inference is critical for reasoning models\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m         }\n\u001b[32m     10\u001b[39m     ]\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(completion.choices[\u001b[32m0\u001b[39m].message.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/groq/resources/chat/completions.py:361\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    180\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    226\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    227\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    229\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    359\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    360\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m    362\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/openai/v1/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    363\u001b[39m         body=maybe_transform(\n\u001b[32m    364\u001b[39m             {\n\u001b[32m    365\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m    366\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m    367\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mexclude_domains\u001b[39m\u001b[33m\"\u001b[39m: exclude_domains,\n\u001b[32m    368\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m    369\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m    370\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m    371\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude_domains\u001b[39m\u001b[33m\"\u001b[39m: include_domains,\n\u001b[32m    372\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m    373\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m    374\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m    375\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m    376\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    377\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m    378\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m    379\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m    380\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_format\u001b[39m\u001b[33m\"\u001b[39m: reasoning_format,\n\u001b[32m    381\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m    382\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msearch_settings\u001b[39m\u001b[33m\"\u001b[39m: search_settings,\n\u001b[32m    383\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m    384\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m    385\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m    386\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m    387\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m    388\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m    389\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m    390\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m    391\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m    392\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m    393\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m    394\u001b[39m             },\n\u001b[32m    395\u001b[39m             completion_create_params.CompletionCreateParams,\n\u001b[32m    396\u001b[39m         ),\n\u001b[32m    397\u001b[39m         options=make_request_options(\n\u001b[32m    398\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m    399\u001b[39m         ),\n\u001b[32m    400\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m    401\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    402\u001b[39m         stream_cls=Stream[ChatCompletionChunk],\n\u001b[32m    403\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/groq/_base_client.py:1222\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1209\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1210\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1217\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1218\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1219\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1220\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1221\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/groq/_base_client.py:1031\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1028\u001b[39m             err.response.read()\n\u001b[32m   1030\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "client = Groq() # Loads the API key automatically from the environment variable\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain why fast inference is critical for reasoning models\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def clone_repo(repo_url: str, target_dir: str):\n",
    "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", repo_url, target_dir], check=True)\n",
    "    tempPath = Path(target_dir)\n",
    "    gitPath = tempPath / \".git\"\n",
    "    subprocess.run([\"rm\", \"-rf\", gitPath], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b2a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_string(file_path: str) -> str:\n",
    "    path = Path(file_path)\n",
    "    if not path.is_file():\n",
    "        raise FileNotFoundError(f\"{file_path} is not a file.\")\n",
    "    return path.read_text(encoding=\"utf-8\", errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2f5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_first_folder(file_path: str) -> str:\n",
    "    parts = Path(file_path).parts\n",
    "    if len(parts) <= 1:\n",
    "        return file_path  # Nothing to remove\n",
    "    return str(Path(*parts[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64b9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dir_rec(dir_path):\n",
    "    files = dict()\n",
    "    from pathlib import Path\n",
    "    root = Path(dir_path)\n",
    "    for child in root.iterdir():\n",
    "        if child.is_file():\n",
    "            files[remove_first_folder(root / child.name)] = read_file_to_string(root / child.name)\n",
    "            print(f\"File: {root / child.name}\")\n",
    "        elif child.is_dir():\n",
    "            print(f\"Directory: {child.name}\")\n",
    "            files = files | read_dir_rec(root / child.name)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc120626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core.storage.storage_context import StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.indices import VectorStoreIndex, load_index_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b773c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "# Set the embedding model, we do this only once when we start the backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba572343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(files_dict):\n",
    "\n",
    "    # Convert dict into list, concatenate file names and contents into one string\n",
    "    documents = [\n",
    "        {\n",
    "            \"path\": name,\n",
    "            \"text\": f\"FILE PATH: \\n{name}, \\nFILE CONTENT: \\n{content}\"\n",
    "        }\n",
    "        for name, content in files_dict.items()\n",
    "    ]\n",
    "\n",
    "    # Load documents into textnodes\n",
    "    text_nodes = []\n",
    "    for d in documents:\n",
    "        new_node = TextNode(text=d[\"text\"], metadata={\"path\" : d[\"path\"]})\n",
    "        text_nodes.append(new_node)\n",
    "\n",
    "    # Create the index\n",
    "    vector_store = SimpleVectorStore() # TODO maybe use a more capable vector store like qdrant? \n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    llm = Ollama(model=\"gemma3:4b\", request_timeout=300)#, base_url=\"http://172.26.44.37:11434\") # \n",
    "\n",
    "    index = VectorStoreIndex(text_nodes)\n",
    "\n",
    "    # Store index in directory\n",
    "    index.storage_context.persist(persist_dir=\"./index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04c2c720",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "model 'gemma3:4b-q4_K_M' not found (status code: 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Ollama\n\u001b[32m      3\u001b[39m llm = Ollama(model=\u001b[33m\"\u001b[39m\u001b[33mgemma3:4b-q4_K_M\u001b[39m\u001b[33m\"\u001b[39m, request_timeout=\u001b[32m300\u001b[39m, stream=\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;66;03m#, base_url=\"http://172.0.0.1:11434\", stream=True)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m response = llm.complete(\u001b[33m\"\u001b[39m\u001b[33mSay hello world.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(chunk.text, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:324\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     result = func(*args, **kwargs)\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    326\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    327\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py:431\u001b[39m, in \u001b[36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[39m\u001b[34m(_self, *args, **kwargs)\u001b[39m\n\u001b[32m    422\u001b[39m event_id = callback_manager.on_event_start(\n\u001b[32m    423\u001b[39m     CBEventType.LLM,\n\u001b[32m    424\u001b[39m     payload={\n\u001b[32m   (...)\u001b[39m\u001b[32m    428\u001b[39m     },\n\u001b[32m    429\u001b[39m )\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     f_return_val = f(_self, *args, **kwargs)\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    433\u001b[39m     callback_manager.on_event_end(\n\u001b[32m    434\u001b[39m         CBEventType.LLM,\n\u001b[32m    435\u001b[39m         payload={EventPayload.EXCEPTION: e},\n\u001b[32m    436\u001b[39m         event_id=event_id,\n\u001b[32m    437\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/llama_index/llms/ollama/base.py:522\u001b[39m, in \u001b[36mOllama.complete\u001b[39m\u001b[34m(self, prompt, formatted, **kwargs)\u001b[39m\n\u001b[32m    518\u001b[39m \u001b[38;5;129m@llm_completion_callback\u001b[39m()\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcomplete\u001b[39m(\n\u001b[32m    520\u001b[39m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, formatted: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs: Any\n\u001b[32m    521\u001b[39m ) -> CompletionResponse:\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_to_completion_decorator(\u001b[38;5;28mself\u001b[39m.chat)(prompt, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/llama_index/core/base/llms/generic_utils.py:179\u001b[39m, in \u001b[36mchat_to_completion_decorator.<locals>.wrapper\u001b[39m\u001b[34m(prompt, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, **kwargs: Any) -> CompletionResponse:\n\u001b[32m    177\u001b[39m     \u001b[38;5;66;03m# normalize input\u001b[39;00m\n\u001b[32m    178\u001b[39m     messages = prompt_to_messages(prompt)\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     chat_response = func(messages, **kwargs)\n\u001b[32m    180\u001b[39m     \u001b[38;5;66;03m# normalize output\u001b[39;00m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_response_to_completion_response(chat_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:324\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     result = func(*args, **kwargs)\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    326\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    327\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py:173\u001b[39m, in \u001b[36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[39m\u001b[34m(_self, messages, **kwargs)\u001b[39m\n\u001b[32m    164\u001b[39m event_id = callback_manager.on_event_start(\n\u001b[32m    165\u001b[39m     CBEventType.LLM,\n\u001b[32m    166\u001b[39m     payload={\n\u001b[32m   (...)\u001b[39m\u001b[32m    170\u001b[39m     },\n\u001b[32m    171\u001b[39m )\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     f_return_val = f(_self, messages, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    175\u001b[39m     callback_manager.on_event_end(\n\u001b[32m    176\u001b[39m         CBEventType.LLM,\n\u001b[32m    177\u001b[39m         payload={EventPayload.EXCEPTION: e},\n\u001b[32m    178\u001b[39m         event_id=event_id,\n\u001b[32m    179\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/llama_index/llms/ollama/base.py:339\u001b[39m, in \u001b[36mOllama.chat\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m    330\u001b[39m tools = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    331\u001b[39m \u001b[38;5;28mformat\u001b[39m = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.json_mode \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    333\u001b[39m response = \u001b[38;5;28mself\u001b[39m.client.chat(\n\u001b[32m    334\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    335\u001b[39m     messages=ollama_messages,\n\u001b[32m    336\u001b[39m     stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mformat\u001b[39m=\u001b[38;5;28mformat\u001b[39m,\n\u001b[32m    338\u001b[39m     tools=tools,\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     options=\u001b[38;5;28mself\u001b[39m._model_kwargs,\n\u001b[32m    340\u001b[39m     keep_alive=\u001b[38;5;28mself\u001b[39m.keep_alive,\n\u001b[32m    341\u001b[39m )\n\u001b[32m    343\u001b[39m response = \u001b[38;5;28mdict\u001b[39m(response)\n\u001b[32m    345\u001b[39m tool_calls = response[\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/llama_index/llms/ollama/base.py:196\u001b[39m, in \u001b[36mOllama._model_kwargs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_model_kwargs\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    194\u001b[39m     base_kwargs = {\n\u001b[32m    195\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.temperature,\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnum_ctx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.get_context_window(),\n\u001b[32m    197\u001b[39m     }\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    199\u001b[39m         **base_kwargs,\n\u001b[32m    200\u001b[39m         **\u001b[38;5;28mself\u001b[39m.additional_kwargs,\n\u001b[32m    201\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/llama_index/llms/ollama/base.py:206\u001b[39m, in \u001b[36mOllama.get_context_window\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_context_window\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.context_window == -\u001b[32m1\u001b[39m:\n\u001b[32m    205\u001b[39m         \u001b[38;5;66;03m# Try to get the context window from the model info if not set\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         info = \u001b[38;5;28mself\u001b[39m.client.show(\u001b[38;5;28mself\u001b[39m.model).modelinfo\n\u001b[32m    207\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m info.items():\n\u001b[32m    208\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcontext_length\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/ollama/_client.py:599\u001b[39m, in \u001b[36mClient.show\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: \u001b[38;5;28mstr\u001b[39m) -> ShowResponse:\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m    600\u001b[39m     ShowResponse,\n\u001b[32m    601\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    602\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m/api/show\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    603\u001b[39m     json=ShowRequest(\n\u001b[32m    604\u001b[39m       model=model,\n\u001b[32m    605\u001b[39m     ).model_dump(exclude_none=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    606\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/ollama/_client.py:178\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28mself\u001b[39m._request_raw(*args, **kwargs).json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ask-my-repo-env/lib/python3.11/site-packages/ollama/_client.py:122\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m    124\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mResponseError\u001b[39m: model 'gemma3:4b-q4_K_M' not found (status code: 404)"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"gemma3:4b-q4_K_M\", request_timeout=300, stream=True)#, base_url=\"http://172.0.0.1:11434\", stream=True)\n",
    "\n",
    "response = llm.complete(\"Say hello world.\")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18c6436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_index():\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./index\")\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    query=\"What are the methods that make up the genetic algorithm?\"\n",
    "    query = \"How did they center the div?\"\n",
    "    query = \"how does the game loop work?\"\n",
    "\n",
    "    retriever_engine = index.as_retriever(similarity_top_k=10)\n",
    "    retrieval_results = retriever_engine.retrieve(query)\n",
    "    retrieved_drawing_ids = [n.node.metadata[\"path\"] for n in retrieval_results]\n",
    "    print(retrieved_drawing_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5827f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_and_read(repo_url):\n",
    "    clone_repo(repo_url=repo_url, target_dir=\"./temp\")\n",
    "    parsed_files = read_dir_rec(\"./temp\")\n",
    "    print(parsed_files)\n",
    "    create_index(parsed_files)\n",
    "    query_index() \n",
    "    subprocess.run([\"rm\", \"-rf\", \"./temp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a7d99d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into './temp'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: src\n",
      "File: temp/src/pipe.js\n",
      "File: temp/src/main.js\n",
      "File: temp/src/bird.js\n",
      "File: temp/src/consts.js\n",
      "File: temp/src/mlp.js\n",
      "File: temp/src/genetic_utils.js\n",
      "File: temp/index.html\n",
      "File: temp/style.css\n",
      "File: temp/README.md\n",
      "{'src/pipe.js': 'const pipeWidth = 50;\\nconst pipeGap = 120; \\nconst spawnMargin = 20; // Margin on top/bottom to make sure pipe gap is not at the very edge of the canvas\\n\\nexport class Pipe {\\n  constructor(gapY, canvas) {\\n    this.x = canvas.width;\\n    this.gapY = gapY;\\n    this.width = pipeWidth;\\n    this.gap = pipeGap;\\n  }\\n\\n  draw(ctx, canvas) {\\n    ctx.fillStyle = \"green\";\\n    // Top part of pipe\\n    ctx.fillRect(this.x, 0, this.width, this.gapY);\\n    // Bottom part of pipe\\n    ctx.fillRect(\\n      this.x,\\n      this.gapY + this.gap,\\n      this.width,\\n      canvas.height - (this.gapY + this.gap)\\n    );\\n  }\\n\\n  // create a new pipe with random gap\\n  static spawn(canvas) {\\n    const minY = spawnMargin;\\n    const maxY = canvas.height - pipeGap - spawnMargin;\\n    const gapY = Math.random() * (maxY - minY) + minY;\\n    return new Pipe(gapY, canvas);\\n  }\\n}\\n', 'src/main.js': 'import { Pipe } from \\'./pipe.js\\';\\nimport { Bird } from \\'./bird.js\\';\\nimport { randomGenome , generateNewBirdsGenetic} from \\'./genetic_utils.js\\';\\nimport { canvas, ctx , getBirdsPerEpoch, setBirdsPerEpoch, setInputFeatures,getInputFeatures, setHiddenSize} from \\'./consts.js\\';\\n\\nconst birdX = 150; // x-position of the birds, which are constant\\nlet pipes = [];\\nlet birds = [];\\nlet frame = 0;\\nlet epoch = 1;\\nlet alive = getBirdsPerEpoch();\\nlet paused = false;\\nconst epochTextField = document.getElementById(\"epoch\"); \\nepochTextField.innerText = `Epoch ${epoch}`;\\nconst aliveTextField = document.getElementById(\"alivecount\");\\naliveTextField.innerText = `Alive: ${alive};`\\nconst scoreTextField = document.getElementById(\"score\");\\nscoreTextField.innerText = `Score: ${frame}`;\\n\\n\\n\\ndocument.addEventListener(\"DOMContentLoaded\", function(){\\n    document.getElementById(\"pauseButton\").addEventListener(\"click\", function(){changePaused()});\\n})\\n\\nfunction changePaused(){\\n    paused = !paused\\n}\\n\\ndocument.addEventListener(\"DOMContentLoaded\", function(){\\n    document.getElementById(\"restartButton\").addEventListener(\"click\",function(){ resetGame()});\\n})\\n\\nfunction getSelectedFeatures() {\\n  const checkboxes = document.querySelectorAll(\\'input[name=\"inputFeatures\"]:checked\\');\\n  let newInputFeatures = Array.from(checkboxes).map(cb => cb.value);\\n\\n  if (newInputFeatures.length === 0) {\\n    alert(\"You must select at least one input feature.\");\\n    return;\\n  }\\n  setInputFeatures(newInputFeatures);\\n  \\n  \\n}\\n\\n\\n\\nfunction initPipes() {\\n    pipes = []\\n    for(let i = -100; i < 600; i += 200){\\n        const newPipe = Pipe.spawn(canvas);\\n        newPipe.x = i;\\n        pipes.push(newPipe);\\n    }\\n}\\n\\n\\n\\n// For the first epoch, all birds genomes are random\\nfunction initBirdsRandom(){\\n    for(let i = 0; i < getBirdsPerEpoch(); i++){\\n        let bird = new Bird(canvas.height / 2, randomGenome());\\n        birds.push(bird);\\n    }\\n}\\n\\nfunction updatePipes() {\\n    // Remove Pipe that crossed x < -200 and spawn a new Pipe at x = 600 instead\\n    const beforeCount = pipes.length;\\n    pipes = pipes.filter(pipe => pipe.x > -200);\\n    if (pipes.length < beforeCount){\\n        const newPipe = Pipe.spawn(canvas);\\n        newPipe.x = 600;\\n        pipes.push(newPipe);\\n    }\\n    // Move pipes\\n    pipes.forEach(pipe => {\\n        pipe.x += -2;\\n    });\\n}\\nfunction updateBirds(){\\n    let currPipe = findCurrentPipe(); // This is always the next pipe the birds could potentially collide with\\n    const normGap = (currPipe.gapY / 600)*2 -1; // Normalize to [-1, 1] to improve MLP performance\\n    const normDist = ((currPipe.x - 100)/200) * 2 - 1;\\n\\n    birds.forEach(bird => {\\n        // Collision with current Pipe\\n        if ((birdX + bird.radius > currPipe.x) && (birdX - bird.radius < currPipe.x + currPipe.width)){\\n            if ((bird.y - bird.radius < currPipe.gapY) || (bird.y + bird.radius > currPipe.gapY + currPipe.gap)){\\n                if(bird.alive){\\n                    bird.alive = false;\\n                    bird.fitness = frame;\\n                }\\n            }\\n        }\\n        //check collision with floor or ceiling\\n        if ((bird.y < 0 ) || (bird.y > canvas.height)){\\n            if(bird.alive){\\n            bird.alive = false;\\n            bird.fitness=frame;\\n            }\\n        }\\n        // Update bird\\n        bird.update(normGap, normDist);\\n    });\\n\\n    //check if all birds died, if yes start new Epoch\\n    const aliveCount = birds.filter(b => b.alive).length;\\n    aliveTextField.innerText = `Alive: ${aliveCount}`\\n    //console.log(aliveCount);\\n    if (aliveCount == 0 || frame > 1500){ //force a new epoch every 1500 frames \\n        resetEpoch();\\n    }\\n}\\n\\nfunction resetEpoch(){\\n    initPipes();\\n    birds = generateNewBirdsGenetic(birds);\\n    epoch++;\\n    frame = 0;\\n    epochTextField.innerText = `Epoch ${epoch}`;\\n    scoreTextField.innerText = `Score: ${frame}`;\\n}\\n\\nfunction resetGame(){\\n    const newBirdsPerEpoch = document.getElementById(\"numBirdsSelect\").value;\\n    const newHiddenSize = document.getElementById(\"hiddenSizeSelect\").value;\\n    setHiddenSize(newHiddenSize);\\n    getSelectedFeatures();\\n    setBirdsPerEpoch(parseInt(newBirdsPerEpoch));\\n    //console.log(\"reset\");\\n    pipes = [];\\n    birds = [];\\n    frame = 0;\\n    epoch = 1;\\n    alive = 1000;\\n    paused = false;\\n    epochTextField.innerText = `Epoch: ${epoch}`;\\n    aliveTextField.innerText = `Alive: ${alive}`;\\n    scoreTextField.innerText = `Score: ${frame}`;\\n    initPipes();\\n    initBirdsRandom();\\n\\n}\\n\\nfunction findCurrentPipe(){\\n    for(let i = 0; i < pipes.length; i++){\\n        if (pipes[i].x > 100) {\\n            return pipes[i];\\n        }\\n    }\\n}\\n\\nfunction drawPipesAndBirds(){\\n    pipes.forEach(pipe => pipe.draw(ctx, canvas));\\n    birds.forEach(bird => bird.draw(ctx));\\n}\\n\\nfunction loop(){\\n    //console.log(paused)\\n    if(!paused){\\n\\n        ctx.clearRect(0, 0, canvas.clientWidth, canvas.height);\\n        updatePipes();\\n        updateBirds();\\n        drawPipesAndBirds();\\n        //requestAnimationFrame(loop);\\n        frame++;\\n    scoreTextField.innerText = `Score: ${frame}`;\\n    }\\n    requestAnimationFrame(loop);\\n}\\n\\ninitPipes();\\ninitBirdsRandom();\\nloop();\\n', 'src/bird.js': 'import { getInputFeatures , getHiddenSize } from \"./consts.js\";\\nimport { MLP } from \"./mlp.js\";\\n\\nconst birdRadius = 10;\\n\\n\\nexport class Bird {\\n    constructor(y, genome) {\\n        this.y = y;\\n        this.radius = birdRadius;\\n        this.genome = genome;\\n        this.velocity = 0;\\n        this.alive = true;\\n        this.fitness = 0;\\n        this.mlp = new MLP(genome, getInputFeatures().length, getHiddenSize());\\n    }\\n\\n    update(normGap, normDist){\\n        if (this.alive){\\n            let inputs = []\\n            let normY = (this.y / 600)*2 - 1;\\n            //let inputs = [this.y, this.velocity, normGap, normDist];\\n            let diff = (normGap - normY) / 2;\\n            let inputFeatures = getInputFeatures();\\n            let normVel = (this.velocity + 8) / 16 - 1; \\n            if (inputFeatures.includes(\"diff\")){\\n                inputs.push((normGap- normY) / 2);\\n            }\\n            if (inputFeatures.includes(\"cHeight\")){\\n                inputs.push(normY);\\n            }\\n            if (inputFeatures.includes(\"pHeight\")){\\n                inputs.push(normGap);\\n            }\\n            if(inputFeatures.includes(\"distance\")){\\n                inputs.push(normDist);\\n            }\\n            if(inputFeatures.includes(\"velocity\")){\\n                inputs.push(normVel); //TODO normalize velocity\\n\\n            }\\n            console.log(inputs);\\n            //inputs = [diff, normDist] // Currently best performing setup with just height difference and distance as inputs\\n            const out = this.mlp.forward(inputs);\\n            console.log(out);\\n            if (out > 0.5) {\\n                this.velocity = -8; // If mlp outputs 1, the bird will jump\\n            }\\n            this.velocity += 0.5; // Apply gravity upwards since y-coords are inverted\\n            this.y += this.velocity; // Move bird according to velocity\\n        }\\n    }\\n\\n    draw(ctx){\\n        if (this.alive){\\n            ctx.beginPath();\\n            ctx.arc(150, this.y, 10, 0, 2*Math.PI);\\n            ctx.fillStyle = \"rgba(255,0,0,0.5)\";\\n            ctx.fill();\\n        }\\n    }\\n}', 'src/consts.js': 'export const canvas = document.getElementById(\"gameCanvas\");\\nexport const ctx = canvas.getContext(\"2d\");\\n\\nlet birdsPerEpoch = 100;\\nlet inputFeatures = [\"diff\", \"distance\"];\\nlet hiddenSize = 3;\\n\\n\\nexport function getBirdsPerEpoch() { return birdsPerEpoch; }\\nexport function setBirdsPerEpoch(val) { birdsPerEpoch = val; }\\n\\nexport function getInputFeatures() { return inputFeatures; }\\nexport function setInputFeatures(val) { inputFeatures = val; }\\n\\nexport function getHiddenSize() { return hiddenSize; }\\nexport function setHiddenSize(val) { hiddenSize = val; }', 'src/mlp.js': \"// To convert output neuron to binary activation value\\nfunction sigmoid(x) {\\n    return 1 / (1 + Math.exp(-x));\\n}\\n\\nfunction relu(x) {\\n    return Math.max(0, x);\\n}\\nexport class MLP {\\n    constructor(genome, inputSize, hiddenSize) {\\n        // Genomes are array of length inputSize * hiddenSize + hiddenSize + hiddenSize * 1 + 1 (since outputSize is 1)\\n        this.inputSize = inputSize;\\n        this.hiddenSize = hiddenSize;\\n\\n        // Extract each layers weights and biases from the Genome\\n        let offset = 0;\\n        this.w1 = []; \\n        for (let i = 0; i < this.hiddenSize; i++) {\\n            this.w1.push(genome.slice(offset, offset + this.inputSize));\\n            offset += this.inputSize;\\n        }\\n\\n        this.b1 = genome.slice(offset, offset + this.hiddenSize);\\n        offset += this.hiddenSize;\\n\\n        this.w2 = genome.slice(offset, offset + this.hiddenSize);\\n        offset += this.hiddenSize;\\n\\n        this.b2 = genome[offset]; \\n    }\\n\\n    forward(inputs) {\\n        // Pass inputs through hidden layer\\n        let hidden = [];\\n        for (let i = 0; i < this.hiddenSize; i++) {\\n            let sum = this.b1[i]; // Start with biases which are extra values that don't come from the input layer\\n            for (let j = 0; j < this.inputSize; j++) {\\n                sum += this.w1[i][j] * inputs[j];\\n            }\\n            hidden.push(relu(sum));\\n        }\\n        // Pass hidden states through output layer\\n        let output = this.b2;\\n        for (let i = 0; i < this.hiddenSize; i++) {\\n            output += this.w2[i] * hidden[i];\\n        }\\n        return sigmoid(output); // Binary activation\\n    } \\n}\\n\\n\", 'src/genetic_utils.js': 'import { Bird} from \"./bird.js\";\\nimport { canvas , getBirdsPerEpoch, getHiddenSize, getInputFeatures } from \"./consts.js\";\\n    \\n// Generate a random Genome\\n// In our model, a genome is just an Array where each value is in [-1, 1] and represents one weight in the MLP\\nexport function randomGenome() {\\n  let inputSize = getInputFeatures().length;\\n  let hiddenSize = getHiddenSize();\\n  let l = inputSize * hiddenSize + hiddenSize + hiddenSize * 1 + 1;\\n  return Array.from({ length: l }, () => Math.random() * 2 - 1);\\n}\\n\\nfunction crossover(g1, g2) {\\n  // For each of our features, pick it randomly from either parent\\n  const child = g1.map((g, i) => (Math.random() < 0.5 ? g : g2[i]));\\n  return mutate(child);  //mutate resulting child\\n}\\n// Randomly change some features slightly\\nfunction mutate(genome) {\\n  return genome.map(w =>\\n    Math.random() < 0.1\\n      ? w + (Math.random() * 2 - 1) * 0.1\\n      : w\\n  );\\n}\\nexport function generateNewBirdsGenetic(birds){\\n    const nextGen = [];\\n    //sort birds by fitness\\n    const sortedBirds = birds.slice()\\n    .sort((a, b) => b.fitness - a.fitness);\\n\\n    //best ten birds stay the same\\n    for (let i = 0; i < 0; i ++){\\n        nextGen.push(sortedBirds[0], sortedBirds[1]);\\n    }\\n    // Filter top 10 birds genomes\\n    const topGenomes = sortedBirds.slice(0, 10).map(bird => bird.genome);\\n    // Run crossover\\n    while (nextGen.length < getBirdsPerEpoch()) {\\n    \\n        const parent1 = topGenomes[Math.floor(Math.random() * topGenomes.length)];\\n        const parent2 = topGenomes[Math.floor(Math.random() * topGenomes.length)];\\n        nextGen.push(new Bird(canvas.height / 2, crossover(parent1, parent2)));\\n    }\\n    birds = [];\\n    birds = nextGen;\\n    return birds;\\n}', 'index.html': '<!DOCTYPE html>\\n<html>\\n<head>\\n  <title>Flappy Evolve</title>\\n  <style>\\n    canvas { border:1px solid black; display:block; margin:auto }\\n  </style>\\n  \\n  <link rel=\"stylesheet\" href=\"style.css\" >\\n</head>\\n<body>\\n  <div class=\"wrapper\">\\n  <div class=\"panel\">\\n  <canvas id=\"gameCanvas\" width=\"600\" height=\"600\"></canvas>\\n  </div>\\n  <div class=\"panel\">\\n  <p id=\"epoch\"></p>\\n  <p id=\"alivecount\"></p>\\n  <p id = \"score\"></p>\\n  <button id=\"pauseButton\">Play/Pause</button>\\n    <div class=\"subpanel\">\\n    <div class=\"subpanel-title\">Change Simulation Parameters</div>\\n  <label for=\"numBirdsSelect\">Number of birds per epoch:</label>\\n  <select id=\"numBirdsSelect\">\\n    <option value=\"50\">50</option>\\n    <option value=\"100\">100</option>\\n    <option value=\"200\">200</option>\\n  </select>\\n  <label for=\"hiddenSizeSelect\">Size of MLP hidden layer:</label>\\n  <select id=\"hiddenSizeSelect\">\\n    <option value=\"2\">2</option>\\n    <option value=\"3\">3</option>\\n    <option value=\"4\">4</option>\\n    <option value=\"5\">5</option>\\n  </select>\\n  <div class=\"subpanel-title\">Select input features</div>\\n  <form id=\"inputFeaturesSelect\">\\n    <label><input type=\"checkbox\" name=\"inputFeatures\" value=\"cHeight\">Bird height</label><br>\\n    <label><input type=\"checkbox\" name=\"inputFeatures\" value=\"pHeight\">Next pipe height</label><br>\\n    <label><input type=\"checkbox\" name=\"inputFeatures\" value=\"distance\" checked>Distance to next pipe</label><br>\\n    <label><input type=\"checkbox\" name=\"inputFeatures\" value=\"diff\" checked>Height difference to next pipe</label><br>\\n    <label><input type=\"checkbox\" name=\"inputFeatures\" value=\"velocity\" unchecked>Bird velocity</label><br>\\n  </form>\\n\\n  <p>Restart the simulation for changed parameters to take effect</p>\\n  <button id=\"restartButton\">Restart</button>\\n  <script type=\"module\" src=\"./src/main.js\"></script>\\n  </div>\\n  </div>\\n  <link rel=\"icon\" href=\"data:,\">\\n</body>\\n</html>\\n\\n', 'style.css': 'body {\\n  background-color: #eaeaea;\\n  font-family: monospace;\\n}\\n.wrapper {\\n    margin: auto;\\n    display: flex;\\n    align-items: stretch; /* ensures same height */\\n    gap: 1em;\\n    justify-content: center;\\n}\\ncanvas {\\n  display: block;\\n  width: 600px;\\n  height: 600px;\\n}\\n.canvas-div {\\n  display: inline-block;\\n  width: 600px;\\n  margin: 2em auto;\\n  padding: 1.5em;\\n  background-color: #fff;\\n  border: 2px solid #000;\\n  border-radius: 0;\\n  box-shadow: 4px 4px 0 #000;\\n  color: #111;\\n}\\n\\n.panel {\\n  display: inline-block;\\n  width: 600px;\\n  margin: 2em 0;\\n  padding: 1.5em;\\n  background-color: #fff;\\n  border: 2px solid #000;\\n  border-radius: 0;\\n  box-shadow: 4px 4px 0 #000;\\n  color: #111;\\n}\\n\\n.subpanel {\\n  margin-top: 1.2em;\\n  padding: 1em;\\n  border: 2px dashed #444;\\n  background-color: #fdfdfd;\\n}\\n\\n.subpanel-title {\\n  font-weight: bold;\\n  margin-bottom: 0.5em;\\n  border-bottom: 1px solid #444;\\n  padding-bottom: 0.2em;\\n}\\n\\np {\\n  margin: 0.5em 0;\\n}\\n\\nlabel {\\n  display: block;\\n  margin: 0.4em 0;\\n}\\n\\nselect {\\n  display: block;\\n  width: 100%;\\n  margin-top: 0.2em;\\n  margin-bottom: 1em;\\n  padding: 0.3em;\\n  border: 1px solid #000;\\n  background-color: #fefefe;\\n  font-family: monospace;\\n}\\n\\ninput[type=\"checkbox\"] {\\n  margin-right: 0.5em;\\n}\\n\\nbutton {\\n  font-family: monospace;\\n  background-color: #ccc;\\n  border: 2px solid #000;\\n  padding: 0.4em 1em;\\n  margin-top: 1em;\\n  cursor: pointer;\\n  box-shadow: 2px 2px 0 #000;\\n}\\n\\nbutton:hover {\\n  background-color: #bbb;\\n}\\n', 'README.md': '# Flappy-Evolve\\nAn implementation of the genetic algorithm for learning Flappy Bird, using plain HTML and JavaScript.\\nTry it out here:  \\nhttps://itsmejul.github.io/flappy-evolve/\\n\\n## Running locally\\nYou can clone this repo via  \\n```\\ngit clone git@github.com:itsmejul/flappy-evolve.git\\n```\\nThen, run it by starting a http server, for example using python:\\n```\\npython -m http.server 8000\\n```\\nAnd then visit ``http://localhost:8000`` in your browser to see the simulation.\\n\\n## Evolution of the birds\\nEach \"bird\" consists of a small MLP with just one hidden layer, which will, during inference, receive the selected input features as inputs. The MLP has one output neuron where we use a sigmoid function to decide whether it should activate or not, based on the inputs. We run this inference once every frame for every bird.\\nThe genome of each bird is represented by an Array of length (input_size*hidden_size + hidden_size + hidden_size * output_size * output_size), which contains all the weights for the weights and biases.\\nEach epoch, we save the score (how long did a bird survive?) for each bird, and then run the genetic algorithm accordingly.\\n## Algorithm\\nFor the first epoch, all genomes are created randomly. For each folliowing epoch, we create the next generation by running the genetic algorithm, which consists of these steps:\\n* Selection: We select the top-k best performing individuals\\n* Crossover: We breed the next generation by pickung two parents from the selected top-k birds, and then randomly combining their weights\\n* Mutation: Finally, for each weight in each genome, there is a small chance that it will be modified by a small value\\n\\n## Challenges\\nIt is not trivial to find a balance between more mutation per epoch and more stable epochs.\\nIf the birds converge too fast (because there is not enough variety in the crossover parents or not enough mutation), then there is a high likelihood to land in a local\\nminimum. In that case, the parameters are too strict and it is not possible for the birds to mutate in a way to leave that local minimum.\\n\\nOn the other hand, if we allow too much mutation, we might not converge at all, even if we find a \"perfect\" individual. In this case, some percentage of the population will die at the start of every epoch, because the random mutations can produce individuals which perform worse than the best-performing individuals of the previous generation.\\n'}\n",
      "['src/consts.js', 'index.html', 'src/main.js', 'src/genetic_utils.js', 'src/bird.js', 'src/mlp.js', 'README.md', 'src/pipe.js', 'style.css']\n"
     ]
    }
   ],
   "source": [
    "clone_and_read(\"https://github.com/itsmejul/flappy-evolve\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ask-my-repo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
