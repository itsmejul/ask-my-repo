{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96836300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Loads env from .env file\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"Missing GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f176dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo  # pip install gitpython\n",
    "\n",
    "#Repo.clone_from(\"https://github.com/itsmejul/flappy-evolve\", \"./dir\")\n",
    "#Repo.clone_from(\"https://github.com/syn-ce/juliasetexplorer\", \"./temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e8e9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def clone_repo(repo_url: str, target_dir: str):\n",
    "    #subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", repo_url, target_dir], check=True, stdout=subprocess.DEVNULL,stderr=subprocess.DEVNULL)\n",
    "    #tempPath = Path(target_dir)\n",
    "    #gitPath = tempPath / \".git\"\n",
    "    #subprocess.run([\"rm\", \"-rf\", gitPath], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    from git import Repo\n",
    "    Repo.clone_from(repo_url, target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c7b2a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_string(file_path: str) -> str:\n",
    "    path = Path(file_path)\n",
    "    if not path.is_file():\n",
    "        raise FileNotFoundError(f\"{file_path} is not a file.\")\n",
    "    return path.read_text(encoding=\"utf-8\", errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c2f5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_first_folder(file_path: str) -> str:\n",
    "    parts = Path(file_path).parts\n",
    "    if len(parts) <= 1:\n",
    "        return file_path  # Nothing to remove\n",
    "    return str(Path(*parts[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f64b9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dir_rec(dir_path):\n",
    "    files = dict()\n",
    "    from pathlib import Path\n",
    "    root = Path(dir_path)\n",
    "    for child in root.iterdir():\n",
    "        if child.is_file():\n",
    "            print(\"A\")\n",
    "            files[remove_first_folder(root / child.name)] = read_file_to_string(root / child.name)\n",
    "            print(f\"File: {root / child.name}\")\n",
    "        elif child.is_dir():\n",
    "            print(f\"Directory: {child.name}\")\n",
    "            files = files | read_dir_rec(root / child.name)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc120626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core.storage.storage_context import StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.indices import VectorStoreIndex, load_index_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b773c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "# Set the embedding model, we do this only once when we start the backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8306768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_directory_documents(path):\n",
    "    from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "    documents = SimpleDirectoryReader(\"./temp\").load_data()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f80629bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(documents):\n",
    "\n",
    "\n",
    "    # Create the index\n",
    "    vector_store = SimpleVectorStore() # TODO maybe use a more capable vector store like qdrant? \n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    llm = Ollama(model=\"gemma3:4b\", request_timeout=300)#, base_url=\"http://172.26.44.37:11434\") # \n",
    "\n",
    "    index = VectorStoreIndex(documents)\n",
    "\n",
    "    # Store index in directory\n",
    "    index.storage_context.persist(persist_dir=\"./index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba572343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_old(files_dict):\n",
    "\n",
    "    # Convert dict into list, concatenate file names and contents into one string\n",
    "    documents = [\n",
    "        {\n",
    "            \"path\": name,\n",
    "            \"text\": f\"FILE PATH: \\n{name}, \\nFILE CONTENT: \\n{content}\"\n",
    "        }\n",
    "        for name, content in files_dict.items()\n",
    "    ]\n",
    "\n",
    "    # Load documents into textnodes\n",
    "    text_nodes = []\n",
    "    for d in documents:\n",
    "        new_node = TextNode(text=d[\"text\"], metadata={\"path\" : d[\"path\"]})\n",
    "        text_nodes.append(new_node)\n",
    "\n",
    "    # Create the index\n",
    "    vector_store = SimpleVectorStore() # TODO maybe use a more capable vector store like qdrant? \n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    llm = Ollama(model=\"gemma3:4b\", request_timeout=300)#, base_url=\"http://172.26.44.37:11434\") # \n",
    "\n",
    "    index = VectorStoreIndex(text_nodes)\n",
    "\n",
    "    # Store index in directory\n",
    "    index.storage_context.persist(persist_dir=\"./index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18c6436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_index(query):\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./index\")\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    #query=\"What are the methods that make up the genetic algorithm?\"\n",
    "    #query = \"How did they center the div?\"\n",
    "    #query = \"how does the game loop work?\"\n",
    "    \n",
    "    retriever_engine = index.as_retriever(similarity_top_k=10)\n",
    "    retrieval_results = retriever_engine.retrieve(query)\n",
    "    retrieved_drawing_ids = [n.node.metadata[\"file_path\"] for n in retrieval_results]\n",
    "    print(retrieved_drawing_ids)\n",
    "    print([n.node.text for n in retrieval_results][:3])\n",
    "    top_3_results = [n.node.text for n in retrieval_results][:3]\n",
    "    return top_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7be7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(retrieval_results, query):\n",
    "    context = \"\"\n",
    "    for result in retrieval_results:\n",
    "        context += result\n",
    "    from groq import Groq\n",
    "    client = Groq() # Loads the API key automatically from the environment variable\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{context}\\n {query}\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5827f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_and_read(repo_url, query):\n",
    "    clone_repo(repo_url=repo_url, target_dir=\"./temp\")\n",
    "    #parsed_files = read_dir_rec(\"./temp\")\n",
    "    #print(parsed_files)\n",
    "    documents = read_directory_documents(\"./temp\")\n",
    "    create_index(documents)\n",
    "    retrieval_results = query_index(query)\n",
    "    llm_response = query_llm(query, retrieval_results)\n",
    "    \n",
    "    subprocess.run([\"rm\", \"-rf\", \"./temp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "142d23b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/julian/dev/ask-my-repo/flask-service/temp/README.md', '/home/julian/dev/ask-my-repo/flask-service/temp/CHANGELOG.md', '/home/julian/dev/ask-my-repo/flask-service/temp/Dockerfile', '/home/julian/dev/ask-my-repo/flask-service/temp/INSTALL.md', '/home/julian/dev/ask-my-repo/flask-service/temp/docker-bake.hcl', '/home/julian/dev/ask-my-repo/flask-service/temp/mise.toml', '/home/julian/dev/ask-my-repo/flask-service/temp/LICENSE.txt', '/home/julian/dev/ask-my-repo/flask-service/temp/BUILD.md', '/home/julian/dev/ask-my-repo/flask-service/temp/VERSION']\n",
      "['\\n<p align=\"center\" style=\"text-align: center;\">\\n    <img width=\"400\" style=\"width: 50% !important; max-width: 400px;\" src=\"assets/getml_logo_dark.png#gh-dark-mode-only\" />\\n    <img width=\"400\" style=\"width: 50% !important; max-width: 400px;\" src=\"assets/getml_logo.png#gh-light-mode-only\" />\\n</p>\\n\\n<p align=\"center\" style=\"text-align: center;\">\\n        <a href=\"https://getml.com/latest/contact\" target=\"_blank\">\\n        <img src=\"https://img.shields.io/badge/schedule-a_meeting-blueviolet.svg\" /></a>\\n        <a href=\"mailto:hello@getml.com\" target=\"_blank\">\\n        <img src=\"https://img.shields.io/badge/contact-us_by_mail-orange.svg\" /></a>\\n        <a href=\"LICENSE.txt\" target=\"_blank\">\\n        <img src=\"https://img.shields.io/badge/LICENSE-ELv2-green\" /></a>\\n</p>\\n\\n# getML - Automated Feature Engineering for Relational Data and Time Series\\n\\n## Introduction\\n\\ngetML is a tool for automating feature engineering on relational data and time series. It includes a specifically customized database Engine for this very purpose.\\n\\nThis results in a speedup between _60_ to _1000_ times (see [Benchmarks](#benchmarks)) over other open-source tools like [featuretools](https://www.featuretools.com) and [tsfresh](https://tsfresh.com) for automated feature engineering. Also check out our [demonstrational notebooks](https://getml.com/latest/examples) to see more comparisons.\\n\\n## Table of Contents\\n\\n* [Introduction](#introduction)\\n* [Table of Contents](#table-of-contents)\\n* [Quick Start](#quick-start)\\n* [Key benefits of using getML](#key-benefits-of-using-getml)\\n  * [Features generate by getML](#features-generate-by-getml)\\n  * [Documentation](#documentation)\\n* [Benchmarks](#benchmarks)\\n* [Demo notebooks](#demo-notebooks)\\n* [Example](#example)\\n* [Release Notes](#release-notes)\\n* [Development](#development)\\n\\n## Quick Start\\n\\nAs getML is available on [PyPI](https://pypi.org/project/getml), you can install it simply via\\n\\n```bash\\npip install getml\\n```\\n\\n> [!NOTE]\\n> To get started on macOS and Windows, you first need to [start the getML docker service](https://getml.com/latest/install/packages/docker/):\\n> ```sh\\n> # run the lastest version\\n> curl -L https://raw.githubusercontent.com/getml/getml-community/refs/heads/main/runtime/docker-compose.yml | docker compose -f - up\\n> \\n> # run a specific version, e.g. 1.5.1\\n> # curl https://raw.githubusercontent.com/getml/getml-community/1.5.1/runtime/docker-compose.yml | docker compose -f - up\\n> ```\\n\\nCheck out [the Example](#example) and the [demonstrational notebooks](https://getml.com/latest/examples) to get started with getML. A [detailed walkthrough guide](https://getml.com/latest/user_guide/walkthrough) and [the documentation](https://getml.com/latest) will also help you on your way with getML.\\n\\nTo learn, how to build and contribute to getML, check out [BUILD.md](BUILD.md) for instructions on how to build getML from source.\\n\\n## Key benefits of using getML\\n\\nOne big key feature over other tools like [featuretools](https://www.featuretools.com), [tsfresh](https://tsfresh.com) and [prophet](https://facebook.github.io/prophet) is the runtime performance. Our own implementation of propositionalization, FastProp (short for fast propositionalization), reaches improvements of about _60_ to _1000_ times faster run times (see specifically [FastProp Benchmarks](https://getml.com/latest/examples/enterprise-notebooks/fastprop_benchmark) within our notebooks). This leads to faster iterations for data scientists, giving them more time to tweak variables to achieve even better results.\\n\\nFastProp is not only faster, but can also provide an increased accuracy.\\n\\nFor even better accuracy, getML provides advanced algorithms in its [professional and Enterprise feature-sets](https://getml.com/latest/enterprise/benefits), namely [Multirel](https://getml.com/latest/user_guide/concepts/feature_engineering/#feature-engineering-algorithms-multirel), [Relboost](https://getml.com/latest/user_guide/concepts/feature_engineering/#feature-engineering-algorithms-relboost), [Fastboost](https://getml.com/latest/user_guide/concepts/feature_engineering/#feature-engineering-algorithms-fastboost) and [RelMT](https://getml.com/latest/user_guide/concepts/feature_engineering/#feature-engineering-algorithms-relmt).\\n\\nThe standard version includes [preprocessors](https://getml.com/latest/user_guide/concepts/preprocessing) (like CategoryTrimmer, EmailDomain, Imputation, Mapping, Seasonal, Substring, TextFieldSplitter), [predictors](https://getml.com/latest/user_guide/concepts/predicting) (like LinearRegression, LogisticRegression, XGBoostClassifier, XGBoostRegressor) and [hyperparameter optimizer](https://getml.com/latest/user_guide/concepts/hyperopt) (like RandomSearch, LatinHypercubeSearch, GaussianHyperparameterSearch).\\n\\nIt also gives access to [the getML Monitor](https://getml.com/latest/user_guide/concepts/getml_suite/#monitor-concepts), which provides valuable information about projects, pipelines, features, important columns, accuracies, performances, and more. Those information give insights and help understand and improve the results.\\n\\ngetML can [import data from various sources](https://getml.com/latest/user_guide/concepts/importing_data) like CSV, Pandas, JSON, SQLite, MySQL, MariaDB, PostgreSQL, Greenplum, ODBC.\\n\\nWhile the standard version is open source, can be run on your local machine, and gets basic support via EMail and via this repository, it must not be used for productive purposes. The [professional and Enterprise versions](https://getml.com/latest/enterprise/benefits) in contrast allows productive uses, gets also support via phone and chat, offers training sessions, as well as on-premise and cloud hosting, and export and deployment features. Get in [contact via email](mailto:hello@getml.com) or directly [schedule a meeting](https://getml.com/latest/contact).\\n\\n### Features generate by getML\\n\\ngetML generates features for relational data and time series. These include, but are not limited to:\\n\\n* **Various aggregations**, i.e. average, sum, minimum, maximum, quantiles, exponentially weighted moving average, trend, exponentially weighted trends, ...\\n* **Aggregations within a certain time frame**, i.e. maximum in the last 30 days, minimum in the last 7 days\\n* **Seasonal factors from time stamps**, such as month, day of the week, hour, ...\\n* **Seasonal aggregations**, i.e. maximum for the same weekday as the prediction point, minimum for the same hour as the prediction point, ...\\n\\nIn other words, it generates the kind of features you would normally build manually. But it automatically generates thousands of features and then automatically picks the best, saving you a lot of manual work.\\n\\n### Documentation\\n\\nCheck out the full documentation on <https://getml.com/latest>\\n\\n## Benchmarks\\n\\nWe evaluated the performance of [getML\\'s FastProp algorithm](https://getml.com/latest/user_guide/concepts/feature_engineering/#feature-engineering-algorithms-fastprop) against five other open-source tools for automated feature engineering on relational data and time series: [_tsflex_](https://github.com/predict-idlab/tsflex), [_featuretools_](https://www.featuretools.com), [_tsfel_](https://github.com/fraunhoferportugal/tsfel), [_tsfresh_](https://github.com/blue-yonder/tsfresh) and [_kats_](https://github.com/facebookresearch/Kats). The datasets used include:\\n\\n1. Air Pollution\\n    * Hourly data on air pollution and weather in Beijing, China.\\n2. Interstate94\\n    * Hourly data on traffic volume on the Interstate 94 from Minneapolis to St. Paul.\\n3. Dodgers\\n    * Five-minute measurements of traffic near Los Angeles, affected by games hosted by the LA Dodgers.\\n4. Energy\\n    * Ten-minute measurements of the electricity consumption of a single household.\\n5. Tetouan\\n    * Ten-minute electricity consumption of three different zones in Tetouan City, north Morocco\\n\\nThe plots shown below contain the _runtime per feature_ calculated relative to the runtime per feature of the fastest approach. The fastest approach turns out to be the getML\\'s FastProp, so it gets a value 1.\\n\\nWe observe, that for all datasets, the features produced by the different tools are quite similar, but **getML is 60-1000 times faster** than other open-source tools.\\n\\n<p align=\"center\">\\n    <img style=\"width: 80%\" src=\"assets/benchmarks_plot_linear.png\" />\\n</p>\\n\\nIn fact, the speed-up is so big that we need a logarithmic scale to even see the bar for getML.\\n\\n<p align=\"center\">\\n    <img style=\"width: 80%\" src=\"assets/benchmarks_plot_log.png\" />\\n</p>\\n\\nTo reproduce those results, refer to the [benchmarks folder](benchmarks) in this repository.\\n\\n## Demo notebooks\\n\\nTo experience getML in action, the following example notebooks are provided in the [demo-notebooks](demo-notebooks) directory:\\n\\n| Notebook                                                      | Prediction Type  | Population Size | Data Type   | Target  | Domain           | Difficulty | Comments                                        |\\n| ------------------------------------------------------------- | ---------------- | --------------- | ----------- |-------- | ---------------- | ---------- | ----------------------------------------------- |\\n| [adventure_works.ipynb](demo-notebooks/adventure_works.ipynb) | Classification   | 19,704          | Relational  | Churn   | Customer loyalty | Hard       | Good reference for a complex data model         |\\n| [formula1.ipynb](demo-notebooks/formula1.ipynb)               | Classification   | 31,578          | Relational  | Win     | Sports           | Medium     |                                                 |\\n| [interstate94.ipynb](demo-notebooks/interstate94.ipynb)       | Regression       | 24,096          | Time Series | Traffic | Transportation   | Easy       | Good notebook to get started on time series     |\\n| [loans.ipynb](demo-notebooks/loans.ipynb)                     | Classification   | 682             | Relational  | Default | Finance          | Easy       | Good notebook to get started on relational data |\\n| [robot.ipynb](demo-notebooks/robot.ipynb)                     | Regression       | 15,001          | Time Series | Force   | Robotics         | Medium     |                                                 |\\n| [seznam.ipynb](demo-notebooks/seznam.ipynb)                   | Regression       | 1,462,078       | Relational  | Volume  | E-commerce       | Medium     |                                                 |\\n\\nFor an extensive list of demonstrational and benchmarking notebooks, have a look at [our docs examples section](https://getml.com/latest/examples) or [the notebook source repository](https://github.com/getml/getml-demo).\\n\\n## Example\\n\\nHere is how you can build a complete Data Science pipeline for a time series problem with seasonalities with just a few lines of code:\\n\\n```python\\nimport getml\\n\\ngetml.engine.launch()\\ngetml.set_project(\"interstate94\")\\n\\n# Load the data.\\ntraffic = getml.datasets.load_interstate94(roles=False, units=False)\\n\\n# Set the roles, so getML knows what you want to predict\\n# and which columns you want to use.\\ntraffic.set_role(\"ds\", getml.data.roles.time_stamp)\\ntraffic.set_role(\"holiday\", getml.data.roles.categorical)\\ntraffic.set_role(\"traffic_volume\", getml.data.roles.target)\\n\\n# Generate a train/test split using 2018/03/15 as the cutoff date.\\nsplit = getml.data.split.time(traffic, \"ds\", test=getml.data.time.datetime(2018, 3, 15))\\n\\n# Set up the data:\\n# - We want to predict the traffic volume for the next hour.\\n# - We want to use data from the seven days before the reference date.\\n# - We want to use lagged targets (autocorrelated features are allowed).\\ntime_series = getml.data.TimeSeries(\\n    population=traffic,\\n    split=split,\\n    time_stamps=\"ds\",\\n    horizon=getml.data.time.hours(1),\\n    memory=getml.data.time.days(7),\\n    lagged_targets=True,\\n)\\n\\n# The Seasonal preprocessor extracts seasonal\\n# components from the time stamps.\\nseasonal = getml.preprocessors.Seasonal()\\n\\n# FastProp extracts features from the time series.\\nfast_prop = getml.feature_learning.FastProp(\\n    loss_function=getml.feature_learning.loss_functions.SquareLoss,\\n    num_threads=1,    \\n    num_features=20,\\n)\\n\\n# Use XGBoost for the predictions (it comes out-of-the-box).\\npredictor = getml.predictors.XGBoostRegressor()\\n\\n# Combine them all in a pipeline.\\npipe = getml.pipeline.Pipeline(\\n    tags=[\"memory: 7d\", \"horizon: 1h\", \"fast_prop\"],\\n    data_model=time_series.data_model,\\n    preprocessors=[seasonal],\\n    feature_learners=[fast_prop],\\n    predictors=[predictor],\\n)\\n\\n# Fit on the train set and evaluate on the testing set.\\npipe.fit(time_series.train)\\npipe.score(time_series.test)\\npredictions = pipe.predict(time_series.test)\\n```\\n\\nTo see the full example, check out the Interstate94 notebook ([interstate94.ipynb](https://getml.com/latest/examples/community-notebooks/interstate94)).\\n\\n## Release Notes\\nSee [CHANGELOG.md](CHANGELOG.md) for release notes.\\n\\n## Development\\n### Python venv\\nTo create the virtual environment for the [python api](src/python-api) just run\\n`uv sync` from anywhere in the project. If you have \\n[mise hooked into your shell](https://mise.jdx.dev/getting-started.html#activate-mise) the \\nenvironment will be activated automatically whenever you your prompt is reloaded\\ninside the project. If you don\\'t have mise hooked into your shell, you can drop\\ninto a shell populated with the environment by running `mise en`.\\n\\n> [!NOTE]\\n> mise doesn\\'t pick up the environment automatically after creating the environment with `uv sync`.\\n> To create and activate the environment in one go run:\\n> ```sh\\n> uv sync && mise en\\n> ```\\n\\n### Building getml\\nRefer to [BUILD.md](BUILD.md) for build instructions.\\n', '# Release Notes\\n\\n## For getML Enterprise & Community editions \\n\\n### 1.5.1   <small>May 15, 2025</small>\\n#### Features\\n- Expose arrow streams\\n- Preserve metadata (roles) of getml dataframes when converting to pandas, arrow, parquet\\n- Support python 3.13\\n#### Developer-focused\\n- More efficient build chain\\n- Expose `GETML_CMAKE_FRESH_PRESET`\\n- Use uv for env mangement\\n- Introduce mise\\n#### Bug fixes\\n- Fix slow parquet writing (by using the exposed arrow stream instead of materializing batches as arrow tables on the engine side)\\n- Fix XGBoost deprecation warnings\\n- Support numpy>=2.0.0\\n- Fix parquet reader for parquet files containing custom metadata\\n- Set unit when setting time_stamp role directly in `from_...` factories\\n\\n\\n### 1.5.0   <small>Sep 24, 2024</small>\\n#### Features\\n- Overhaul and better integration of API documentation and web page:\\n    - Switch from [sphinx](https://www.sphinx-doc.org/en/master/) to [mkdocs](https://www.mkdocs.org/)\\n    - Restructuring of [User Guide](https://getml.com/latest/user_guide/), multiple amendments to documentation \\n- Introduce strict typing regiment for [feature learning aggregations](https://getml.com/latest/reference/feature_learning/aggregations/) and [loss functions](https://getml.com/latest/reference/feature_learning/loss_functions)\\n- Clean up and maintenance of [example notebooks](https://getml.com/latest/examples/), make them executable in [Colab](https://colab.google/)\\n- More informative progress bar and status updates using [rich](https://github.com/Textualize/rich?tab=readme-ov-file)\\n- Completely reworked IO\\n    - Leveraging [PyArrow](https://arrow.apache.org/docs/python/index.html) to improve reliability, speed and maintainability\\n- Introduce [reflect-cpp](https://github.com/getml/reflect-cpp) for parsing and de/serialization\\n- Introduce overhauled getML Docker runtime [available from Docker Hub](https://hub.docker.com/r/getml/getml), allowing for easy setup\\n  - See [docker-related section of the new getML documentation](https://getml.com/latest/install/packages/docker/) for details\\n#### Developer-focused\\n- Complete rework of the build pipeline (docker and linux native)\\n    - Introduce [CCache](https://ccache.dev/), [conan](https://conan.io/), [vcpkg](https://vcpkg.io/en/)\\n    - User multi-stage docker builds leveraging buildx and buildkit\\n    - Centralized `VERSION`\\n- [Ruff](https://docs.astral.sh/ruff/) for linting and formatting\\n- [Hatch](https://hatch.pypa.io/latest/) for python package management\\n#### Bug fixes\\n- Generalization of [`Placeholder.join`](https://getml.com/latest/reference/data/placeholder/#getml.data.Placeholder.join)\\'s `on` argument \\n- Improved timestamp handling\\n- Slicing improvements\\n    - Slicing of `DataFrames` returned wrong results: Remove short circuit for slices with upper bound\\n    - Introduce set semantics for slicing of `DataFrame` (return empty collections instead of erroring)\\n- Fix displaying of parameter lists with values that exceed the presentable width\\n- Fix displaying of [`DataFrames`](https://getml.com/latest/reference/data/data_frame/) with one row or less\\n- Fix progress bar output on Google Colab\\n\\n### 1.4.0\\t<small>Oct 17, 2023</small>\\n- Accelerated feature learning through [Fastboost](https://getml.com/latest/reference/feature_learning/fastboost)\\n- Improved modelling on huge datasets through [ScaleGBMClassifier](https://getml.com/latest/reference/predictors/scale_gbm_classifier) and [ScaleGBMRegressor](https://getml.com/latest/reference/predictors/scale_gbm_regressor)\\n- Advanced trend aggregations using [EWMATrend aggregations](https://getml.com/latest/reference/feature_learning/aggregations/#getml.feature_learning.aggregations.EWMA_1S)\\n- Faster JSON parsing using YYJSON\\n\\n### 1.3.2\\t<small>Jan 26, 2023</small>\\n- Minor bugfixes\\n\\n### 1.3.1\\t<small>Dec 20, 2022</small>\\n- Implement `tqdm` for progress bars\\n- Minor bugfixes\\n\\n### 1.3.0\\t<small>Aug 28, 2022</small>\\n- Use websockets instead of polling\\n- Size [threshold](https://getml.com/latest/reference/pipeline.Features.to_sql) for better visualization of feature code\\n- Faster reading of memory-mapped data, relevant for all feature learners and predictors\\n- Introduce [CategoryTrimmer](https://getml.com/latest/reference/preprocessors/#getml.preprocessors.CategoryTrimmer) as preprocessor\\n\\n### 1.2.0\\t<small>May 20, 2022</small>\\n- Support for [SQL transpilation](https://getml.com/latest/reference/pipeline/dialect/): TSQL, Postgres, MySQL, BigQuery, Spark\\n- Support for memory mapping\\n\\n### 1.1.0\\t<small>Nov 21, 2021</small>\\n- Enhance data processing by introducing Spark (e.g. [spark_sql](https://getml.com/latest/reference/pipeline/dialect/#getml.pipeline.dialect.spark_sql)) and Arrow (e.g. [from_arrow()](https://getml.com/latest/reference/data/data_frame/#getml.data.DataFrame.from_arrow))\\n- Integrate Vcpkg for dependency management\\n- Improve code transpilation for seasonal variables\\n- Better control of predictor training and hyperparamter optimization through introduction of early stopping (e.g. in [ScaleGBMClassifier](https://getml.com/latest/reference/predictors/scale_gbm_classifier/))\\n- Introduce [TREND](https://getml.com/latest/reference/feature_learning/aggregations/#getml.feature_learning.aggregations.TREND) aggregation\\n- Better progress logging\\n\\n### 1.0.0\\t<small>Sep 23, 2021</small>\\n- Introduction of [Containers](https://getml.com/latest/reference/data/container/) for data storage\\n- Complete overhaul of the API including [Views](https://getml.com/latest/reference/data/view/), [StarSchema](https://getml.com/latest/reference/data/star_schema/), [TimeSeries](https://getml.com/latest/reference/data/time_series/)\\n- Add [subroles](https://getml.com/latest/reference/data/subroles/) for fine grained data control\\n- Improved model evaluation through [Plots](https://getml.com/latest/reference/pipeline/plots/) and [Scores](https://getml.com/latest/reference/pipeline/scores_container/) container\\n- Introduce [slicing](https://getml.com/latest/reference/data/view/#getml.data.View.where) of Views\\n- Add [datetime()](https://getml.com/latest/reference/data/time/#getml.data.time.datetime) utility\\n\\n### 0.16.0 <small>May 25, 2021</small>\\n- Add the [Mapping](https://getml.com/latest/reference/preprocessors/#getml.preprocessors.Mapping) and [TextFieldSplitter](https://getml.com/latest/reference/preprocessors/#getml.preprocessors.TextFieldSplitter) preprocessors\\n\\n### 0.15.0 <small>Feb 23, 2021</small>\\n- Add the [Fastprop](https://getml.com/latest/reference/feature_learning/fastprop/) feature learner\\n- Overhaul the way RelMT and Relboost generate features, making them more efficient\\n\\n### 0.14.0 <small>Jan 18, 2021</small>\\n- Significant improvement of  project management:\\n    -  [project.restart()](https://getml.com/latest/reference/project/#getml.project.attrs.restart), [project.suspend()](https://getml.com/latest/reference/project/#getml.project.attrs.suspend), and [project.switch()](https://getml.com/latest/reference/project/#getml.project.attrs.switch)\\n    - multiple project support\\n- Add custom `__getattr__` and `__dir__` methods to DataFrame, enabling column retrieval through autocomplete\\n\\n### 0.13.0 <small>Nov 13, 2020</small>\\n- Introduce new feature learner: \\n    - RelMTModel [now [RelMT](https://getml.com/latest/reference/feature_learning/relmt/)], \\n    - RelMTTimeSeries [now integrated in [TimeSeries](https://getml.com/latest/reference/data/time_series/)]\\n\\n### 0.12.0 <small>Oct 1, 2020</small>\\n- Extend dataframe handling: [delete()](https://getml.com/latest/reference/data/data_frame/#getml.data.DataFrame.delete), [exists()](https://getml.com/latest/reference/data/#getml.data.exists)\\n- Data set provisioning: [load_air_pollution()](https://getml.com/latest/reference/datasets/datasets/#getml.datasets.load_air_pollution), [load_atherosclerosis()](https://getml.com/latest/reference/datasets/datasets/#getml.datasets.load_atherosclerosis), [load_biodegradability()](https://getml.com/latest/reference/datasets/datasets/#getml.datasets.load_biodegradability), [load_consumer_expenditures()](https://getml.com/latest/reference/datasets/datasets/#getml.datasets.load_consumer_expenditures), [load_interstate94()](https://getml.com/latest/reference/datasets/datasets/#getml.datasets.load_interstate94), [load_loans()](https://getml.com/latest/reference/datasets/datasets/#getml.datasets.load_loans), [load_occupancy()](https://getml.com/latest/reference/datasets/datasets/#getml.datasets.load_occupancy)\\n- High-level hyperopt handlers: [tune_feature_learners()](https://getml.com/latest/reference/hyperopt/#getml.hyperopt.tune_feature_learners), [tune_predictors()](https://getml.com/latest/reference/hyperopt/#getml.hyperopt.tune_predictors)\\n- Improve pipeline functionality: [delete()](https://getml.com/latest/reference/pipeline/#getml.pipeline.delete), [exists()](https://getml.com/latest/reference/pipeline/#getml.pipeline.exists), [Columns](https://getml.com/latest/reference/pipeline/columns/)\\n- Introduce preprocessors: [EmailDomain](https://getml.com/latest/reference/preprocessors/#getml.preprocessors.EmailDomain), [Imputation](https://getml.com/latest/reference/preprocessors/#getml.preprocessors.Imputation), [Seasonal](https://getml.com/latest/reference/preprocessors/#getml.preprocessors.Seasonal), [Substring](https://getml.com/latest/reference/preprocessors/#getml.preprocessors.Substring)\\n\\n### 0.11.1 <small>Jul 13, 2020</small>\\n- Add pipeline functionality: [Pipeline](https://getml.com/latest/reference/pipeline/pipeline/), [list_pipelines()](https://getml.com/latest/reference/pipeline/#getml.pipeline.list_pipelines), [Features](https://getml.com/latest/reference/pipeline/features/), [Metrics](https://getml.com/latest/reference/pipeline/metrics/), [SQLCode](https://getml.com/latest/reference/pipeline/sql_code/), [Scores](https://getml.com/latest/reference/pipeline/scores_container/)\\n- Better control of hyperparameter optimization: [burn_in](https://getml.com/latest/reference/hyperopt/#getml.hyperopt.burn_in), [kernels](https://getml.com/latest/reference/hyperopt/#getml.hyperopt.kernels), [optimization](https://getml.com/latest/reference/hyperopt/#getml.hyperopt.optimization)\\n- Handling of time stamps: [time](https://getml.com/latest/reference/data/time/)\\n- Improve database I/O: [connect_odbc()](https://getml.com/latest/reference/database/database/#getml.database.connect_odbc.connect_odbc), [copy_table()](https://getml.com/latest/reference/database/database/#getml.database.copy_table.copy_table), [list_connections()](https://getml.com/latest/reference/database/database/#getml.database.list_connections.list_connections), [read_s3()](https://getml.com/latest/reference/data/data_frame/#getml.data.DataFrame.read_s3), [sniff_s3()](https://getml.com/latest/reference/database/database/#getml.database.sniff_s3.sniff_s3)\\n- Enable S3 access: [set_s3_access_key_id()](https://getml.com/latest/reference/data/access/#getml.data.access.set_s3_access_key_id), [set_s3_secret_access_key()](https://getml.com/latest/reference/data/access/#getml.data.access.set_s3_secret_access_key)\\n- New Feature Learner: MultirelTimeSeries, RelboostTimeSeries [now both integrated in [TimeSeries](https://getml.com/latest/reference/data/time_series/)]\\n\\n### 0.10.0 <small>Mar 17, 2020</small>\\n- Add [XGBoostClassifier](https://getml.com/latest/reference/predictors/xgboost_classifier/) and [XGBoostRegressor](https://getml.com/latest/reference/predictors/xgboost_regressor/) for improved predictive power\\n- Overhaul of documentation \\n    - Introduction of \"getML in one minute\" (now [Quickstart](https://getml.com/latest/user_guide/quick_start/)) and \"How to use this guide\" (now [User Guide](https://getml.com/latest/user_guide/))\\n    - Introduction of User Guide (now [Concepts](https://getml.com/latest/user_guide/concepts/)) to include data annotation, feature engineering, hyperparameter optimization and more\\n- Integration with additional databases like [Greenplum](https://getml.com/latest/reference/database/database/#getml.database.connect_greenplum.connect_greenplum), [MariaDB](https://getml.com/latest/reference/database/database/#getml.database.connect_mariadb.connect_mariadb), [MySQL](https://getml.com/latest/reference/database/database/#getml.database.connect_mysql.connect_mysql), and extended [PostgreSQL](https://getml.com/latest/reference/database/database/#getml.database.connect_postgres.connect_postgres) support\\n\\n### 0.9.1\\t<small>Mar 17, 2020</small>\\n- Include hotfix for new domain getml.com\\n\\n### 0.9\\t<small>Dec 9, 2019</small>\\n- Rework hyperopt design and handling, added [load_hyperopt()](https://getml.com/latest/reference/hyperopt/#getml.hyperopt.load_hyperopt.load_hyperopt)\\n- Improved dataframe handling: add [to_placeholder()](https://getml.com/latest/reference/data/data_frame/#getml.data.DataFrame.to_placeholder) and [nrows()](https://getml.com/latest/reference/data/data_frame/#getml.data.DataFrame.nrows)\\n\\n### 0.8\\t<small>Oct 22, 2019</small>\\n- Rename Autosql to [Multirel](https://getml.com/latest/reference/feature_learning/multirel/)\\n- Boolean and categorical columns: Add support for boolean columns and operators, along with enhanced categorical column handling.\\n- Introduce API improvements: fitting, saving/loading of models, data transformation\\n- Add support for various aggregation functions such as [MEDIAN](https://getml.com/latest/reference/feature_learning/aggregations/#getml.feature_learning.aggregations.MEDIAN), [VAR](https://getml.com/latest/reference/feature_learning/aggregations/#getml.feature_learning.aggregations.VAR), [STDDEV](https://getml.com/latest/reference/feature_learning/aggregations/#getml.feature_learning.aggregations.STDDEV), and [COUNT_DISTINCT](https://getml.com/latest/reference/feature_learning/aggregations/#getml.feature_learning.aggregations.COUNT_DISTINCT)\\n- Move from closed beta to [pip](https://pypi.org/project/getml/)\\n- Introduce basic hyperopt algorithms: [LatinHypercubeSearch](https://getml.com/latest/reference/hyperopt/latin/), [RandomSearch](https://getml.com/latest/reference/hyperopt/random/)\\n', 'ARG OUTPUT_DIR\\nARG VERSION\\nARG PACKAGE_NAME=\"getml-community-$VERSION-$TARGETARCH-$TARGETOS\"\\nARG BUILD_OR_COPY_ARTIFACTS=\"build\"\\n\\nFROM --platform=$BUILDPLATFORM golang:1.22 AS cli-build\\nARG TARGETOS\\nARG TARGETARCH\\nARG VERSION\\nWORKDIR /cli/src\\nCOPY src/getml-app/src .\\n\\nRUN --mount=type=cache,target=/go/pkg/mod/ \\\\\\n    CGO_ENABLED=0 GOOS=${TARGETOS} GOARCH=${TARGETARCH} go build -o /cli/build/getml-cli -ldflags \"-X main.version=$VERSION\" . \\\\\\n    && mkdir /cli/release \\\\\\n    && cp /cli/build/getml-cli /cli/release/getml-cli\\n\\nFROM scratch AS cli\\nARG PACKAGE_NAME\\nCOPY --from=cli-build /cli/release/getml-cli $PACKAGE_NAME/getML\\n\\nFROM scratch AS export\\nARG PACKAGE_NAME\\nCOPY --from=cli / .\\nCOPY --from=engine-package . .\\nCOPY LICENSE.txt INSTALL.md $PACKAGE_NAME\\nCOPY src/package-build-imports $PACKAGE_NAME\\n\\nFROM --platform=$BUILDPLATFORM python:3.11-slim AS python-base\\nARG TARGETPLATFORM\\nARG BUILDPLATFORM\\nARG PACKAGE_NAME\\nARG VERSION\\nWORKDIR /python-api/src\\nRUN pip install hatch\\nCOPY src/python-api/ .\\nRUN echo $VERSION > getml/VERSION\\nRUN hatch build -t wheel\\nRUN mkdir -p /python-api/src/getml/.getML\\n\\nFROM python-base AS python-base-arm64\\nARG WHEEL_PLATFORM=\"manylinux_2_28_aarch64\"\\n# HACK: Remove the any platform wheel on one of the branches\\n# to avoid multi-platform artifact name collision\\nRUN if [ \"$TARGETPLATFORM\" != \"$BUILDPLATFORM\" ]; then rm -rf dist/*.whl; fi\\n\\nFROM python-base AS python-base-amd64\\nARG WHEEL_PLATFORM=\"manylinux_2_28_x86_64\"\\nRUN if [ \"$TARGETPLATFORM\" != \"$BUILDPLATFORM\" ]; then rm -rf dist/*.whl; fi\\n\\nFROM python-base-$TARGETARCH AS python-build-artifacts\\nCOPY --from=export /$PACKAGE_NAME getml/.getML/$PACKAGE_NAME\\n\\nFROM python-base-$TARGETARCH AS python-copy-artifacts\\nARG OUTPUT_DIR\\nCOPY $OUTPUT_DIR/$PACKAGE_NAME getml/.getML/$PACKAGE_NAME\\n\\nFROM python-${BUILD_OR_COPY_ARTIFACTS}-artifacts AS python-build\\nRUN hatch build -t wheel\\n\\nFROM scratch AS python\\nCOPY --from=python-build python-api/src/dist python-api\\n\\nFROM alpine AS archive-build-artifacts\\nARG PACKAGE_NAME\\nCOPY --from=export / /\\n\\nFROM alpine AS archive-copy-artifacts\\nARG PACKAGE_NAME\\nARG OUTPUT_DIR\\nCOPY $OUTPUT_DIR/$PACKAGE_NAME $PACKAGE_NAME\\n\\nFROM archive-${BUILD_OR_COPY_ARTIFACTS}-artifacts AS archive-export\\nRUN mkdir /out\\nRUN tar czf /out/$PACKAGE_NAME.tar.gz $PACKAGE_NAME\\nWORKDIR /out\\nRUN sha256sum $PACKAGE_NAME.tar.gz > $PACKAGE_NAME.tar.gz.sha256\\n\\nFROM scratch AS archive\\nCOPY --from=archive-export /out/ .\\n\\nFROM scratch AS all\\nCOPY --from=export / .\\nCOPY --from=python / .\\nCOPY --from=archive / .\\n']\n",
      "The fastprop algorithm in getML is implemented in C++ and utilizes a custom database engine to improve performance. The algorithm is used for automated feature engineering on relational data and time series.\n",
      "\n",
      "Here is a high-level overview of how the fastprop algorithm is implemented:\n",
      "\n",
      "1. **Data Preparation**: The algorithm starts by preparing the data for feature engineering. This involves loading the data into the custom database engine and setting the roles for the data (e.g., time stamp, target variable).\n",
      "2. **Feature Generation**: The algorithm then generates features from the data using various techniques such as aggregations, lagged targets, and seasonal components.\n",
      "3. **Feature Selection**: The algorithm selects the most relevant features using a combination of techniques such as correlation analysis, mutual information, and recursive feature elimination.\n",
      "4. **Model Training**: The selected features are then used to train a machine learning model using a chosen algorithm (e.g., XGBoost, linear regression).\n",
      "5. **Hyperparameter Optimization**: The algorithm performs hyperparameter optimization using techniques such as grid search, random search, or Bayesian optimization to find the best hyperparameters for the model.\n",
      "\n",
      "The fastprop algorithm is designed to be highly efficient and scalable, allowing it to handle large datasets and complex feature engineering tasks. The algorithm is also highly customizable, allowing users to specify their own feature engineering techniques, machine learning algorithms, and hyperparameter optimization methods.\n",
      "\n",
      "Here is some sample Python code that demonstrates how to use the fastprop algorithm in getML:\n",
      "```python\n",
      "import getml\n",
      "\n",
      "# Load the data\n",
      "data = getml.datasets.load_interstate94()\n",
      "\n",
      "# Set the roles for the data\n",
      "data.set_role(\"ds\", getml.data.roles.time_stamp)\n",
      "data.set_role(\"traffic_volume\", getml.data.roles.target)\n",
      "\n",
      "# Create a time series object\n",
      "time_series = getml.data.TimeSeries(\n",
      "    population=data,\n",
      "    split=getml.data.split.time(data, \"ds\", test=getml.data.time.datetime(2018, 3, 15)),\n",
      "    time_stamps=\"ds\",\n",
      "    horizon=getml.data.time.hours(1),\n",
      "    memory=getml.data.time.days(7),\n",
      "    lagged_targets=True,\n",
      ")\n",
      "\n",
      "# Create a fastprop feature learner\n",
      "fast_prop = getml.feature_learning.FastProp(\n",
      "    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n",
      "    num_threads=1,\n",
      "    num_features=20,\n",
      ")\n",
      "\n",
      "# Create a pipeline with the fastprop feature learner and an XGBoost predictor\n",
      "pipe = getml.pipeline.Pipeline(\n",
      "    tags=[\"memory: 7d\", \"horizon: 1h\", \"fast_prop\"],\n",
      "    data_model=time_series.data_model,\n",
      "    feature_learners=[fast_prop],\n",
      "    predictors=[getml.predictors.XGBoostRegressor()],\n",
      ")\n",
      "\n",
      "# Fit the pipeline to the training data\n",
      "pipe.fit(time_series.train)\n",
      "\n",
      "# Evaluate the pipeline on the testing data\n",
      "pipe.score(time_series.test)\n",
      "```\n",
      "This code loads the interstate94 dataset, sets the roles for the data, creates a time series object, and defines a fastprop feature learner and an XGBoost predictor. The pipeline is then fitted to the training data and evaluated on the testing data.\n"
     ]
    }
   ],
   "source": [
    "#clone_and_read(\"https://github.com/syn-ce/juliasetexplorer\", \"How are the fractals drawn to the screen in javascript? Reference relevant code snippets\")\n",
    "clone_and_read(\"https://github.com/getml/getml-community\", \"How is the fastprop algorithm implemented?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a7d99d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/julian/dev/ask-my-repo/flask-service/temp/README.md', '/home/julian/dev/ask-my-repo/flask-service/temp/index.html', '/home/julian/dev/ask-my-repo/flask-service/temp/style.css']\n",
      "['# Flappy-Evolve\\nAn implementation of the genetic algorithm for learning Flappy Bird, using plain HTML and JavaScript.\\nTry it out here:  \\nhttps://itsmejul.github.io/flappy-evolve/\\n\\n## Running locally\\nYou can clone this repo via  \\n```\\ngit clone git@github.com:itsmejul/flappy-evolve.git\\n```\\nThen, run it by starting a http server, for example using python:\\n```\\npython -m http.server 8000\\n```\\nAnd then visit ``http://localhost:8000`` in your browser to see the simulation.\\n\\n## Evolution of the birds\\nEach \"bird\" consists of a small MLP with just one hidden layer, which will, during inference, receive the selected input features as inputs. The MLP has one output neuron where we use a sigmoid function to decide whether it should activate or not, based on the inputs. We run this inference once every frame for every bird.\\nThe genome of each bird is represented by an Array of length (input_size*hidden_size + hidden_size + hidden_size * output_size * output_size), which contains all the weights for the weights and biases.\\nEach epoch, we save the score (how long did a bird survive?) for each bird, and then run the genetic algorithm accordingly.\\n## Algorithm\\nFor the first epoch, all genomes are created randomly. For each folliowing epoch, we create the next generation by running the genetic algorithm, which consists of these steps:\\n* Selection: We select the top-k best performing individuals\\n* Crossover: We breed the next generation by pickung two parents from the selected top-k birds, and then randomly combining their weights\\n* Mutation: Finally, for each weight in each genome, there is a small chance that it will be modified by a small value\\n\\n## Challenges\\nIt is not trivial to find a balance between more mutation per epoch and more stable epochs.\\nIf the birds converge too fast (because there is not enough variety in the crossover parents or not enough mutation), then there is a high likelihood to land in a local\\nminimum. In that case, the parameters are too strict and it is not possible for the birds to mutate in a way to leave that local minimum.\\n\\nOn the other hand, if we allow too much mutation, we might not converge at all, even if we find a \"perfect\" individual. In this case, some percentage of the population will die at the start of every epoch, because the random mutations can produce individuals which perform worse than the best-performing individuals of the previous generation.\\n', '<!DOCTYPE html>\\n<html>\\n<head>\\n  <title>Flappy Evolve</title>\\n  <style>\\n    canvas { border:1px solid black; display:block; margin:auto }\\n  </style>\\n  \\n  <link rel=\"stylesheet\" href=\"style.css\" >\\n</head>\\n<body>\\n  <div class=\"wrapper\">\\n  <div class=\"panel\">\\n  <canvas id=\"gameCanvas\" width=\"600\" height=\"600\"></canvas>\\n  </div>\\n  <div class=\"panel\">\\n  <p id=\"epoch\"></p>\\n  <p id=\"alivecount\"></p>\\n  <p id = \"score\"></p>\\n  <button id=\"pauseButton\">Play/Pause</button>\\n    <div class=\"subpanel\">\\n    <div class=\"subpanel-title\">Change Simulation Parameters</div>\\n  <label for=\"numBirdsSelect\">Number of birds per epoch:</label>\\n  <select id=\"numBirdsSelect\">\\n    <option value=\"50\">50</option>\\n    <option value=\"100\">100</option>\\n    <option value=\"200\">200</option>\\n  </select>\\n  <label for=\"hiddenSizeSelect\">Size of MLP hidden layer:</label>\\n  <select id=\"hiddenSizeSelect\">\\n    <option value=\"2\">2</option>\\n    <option value=\"3\">3</option>\\n    <option value=\"4\">4</option>\\n    <option value=\"5\">5</option>\\n  </select>\\n  <div class=\"subpanel-title\">Select input features</div>\\n  <form id=\"inputFeaturesSelect\">\\n    <label><input type=\"checkbox\" name=\"inputFeatures\" value=\"cHeight\">Bird height</label><br>\\n    <label><input type=\"checkbox\" name=\"inputFeatures\" value=\"pHeight\">Next pipe height</label><br>\\n    <label><input type=\"checkbox\" name=\"inputFeatures\" value=\"distance\" checked>Distance to next pipe</label><br>\\n    <label><input type=\"checkbox\" name=\"inputFeatures\" value=\"diff\" checked>Height difference to next pipe</label><br>\\n    <label><input type=\"checkbox\" name=\"inputFeatures\" value=\"velocity\" unchecked>Bird velocity</label><br>\\n  </form>\\n\\n  <p>Restart the simulation for changed parameters to take effect</p>\\n  <button id=\"restartButton\">Restart</button>\\n  <script type=\"module\" src=\"./src/main.js\"></script>\\n  </div>\\n  </div>\\n  <link rel=\"icon\" href=\"data:,\">\\n</body>\\n</html>\\n\\n', 'body {\\n  background-color: #eaeaea;\\n  font-family: monospace;\\n}\\n.wrapper {\\n    margin: auto;\\n    display: flex;\\n    align-items: stretch; /* ensures same height */\\n    gap: 1em;\\n    justify-content: center;\\n}\\ncanvas {\\n  display: block;\\n  width: 600px;\\n  height: 600px;\\n}\\n.canvas-div {\\n  display: inline-block;\\n  width: 600px;\\n  margin: 2em auto;\\n  padding: 1.5em;\\n  background-color: #fff;\\n  border: 2px solid #000;\\n  border-radius: 0;\\n  box-shadow: 4px 4px 0 #000;\\n  color: #111;\\n}\\n\\n.panel {\\n  display: inline-block;\\n  width: 600px;\\n  margin: 2em 0;\\n  padding: 1.5em;\\n  background-color: #fff;\\n  border: 2px solid #000;\\n  border-radius: 0;\\n  box-shadow: 4px 4px 0 #000;\\n  color: #111;\\n}\\n\\n.subpanel {\\n  margin-top: 1.2em;\\n  padding: 1em;\\n  border: 2px dashed #444;\\n  background-color: #fdfdfd;\\n}\\n\\n.subpanel-title {\\n  font-weight: bold;\\n  margin-bottom: 0.5em;\\n  border-bottom: 1px solid #444;\\n  padding-bottom: 0.2em;\\n}\\n\\np {\\n  margin: 0.5em 0;\\n}\\n\\nlabel {\\n  display: block;\\n  margin: 0.4em 0;\\n}\\n\\nselect {\\n  display: block;\\n  width: 100%;\\n  margin-top: 0.2em;\\n  margin-bottom: 1em;\\n  padding: 0.3em;\\n  border: 1px solid #000;\\n  background-color: #fefefe;\\n  font-family: monospace;\\n}\\n\\ninput[type=\"checkbox\"] {\\n  margin-right: 0.5em;\\n}\\n\\nbutton {\\n  font-family: monospace;\\n  background-color: #ccc;\\n  border: 2px solid #000;\\n  padding: 0.4em 1em;\\n  margin-top: 1em;\\n  cursor: pointer;\\n  box-shadow: 2px 2px 0 #000;\\n}\\n\\nbutton:hover {\\n  background-color: #bbb;\\n}\\n']\n",
      "The jumping of the birds and the gravity implementation in the Flappy Bird game are not explicitly described in the provided code snippets. However, I can provide a general explanation of how these features are typically implemented in a Flappy Bird game.\n",
      "\n",
      "### Jumping Mechanism\n",
      "\n",
      "The jumping mechanism in Flappy Bird is usually implemented using a simple physics-based approach. Here's a high-level overview of how it works:\n",
      "\n",
      "1. **Initial Velocity**: When the bird jumps, it is given an initial upward velocity.\n",
      "2. **Gravity**: The bird is constantly being pulled downwards by gravity, which is simulated by applying a downward acceleration to the bird's velocity.\n",
      "3. **Velocity Update**: On each frame, the bird's velocity is updated based on the gravity acceleration.\n",
      "4. **Position Update**: The bird's position is updated based on its velocity.\n",
      "\n",
      "### Gravity Implementation\n",
      "\n",
      "Gravity is typically implemented using a constant acceleration value, which is applied to the bird's velocity on each frame. The gravity acceleration value is usually set to a small negative value (e.g., -0.5 pixels per frame squared) to simulate the downward pull of gravity.\n",
      "\n",
      "Here's some sample JavaScript code to illustrate the jumping mechanism and gravity implementation:\n",
      "```javascript\n",
      "// Bird object\n",
      "let bird = {\n",
      "  x: 100,\n",
      "  y: 100,\n",
      "  vy: 0, // initial velocity\n",
      "  gravity: -0.5, // gravity acceleration\n",
      "  jumpVelocity: 10, // initial jump velocity\n",
      "};\n",
      "\n",
      "// Update bird position and velocity\n",
      "function updateBird() {\n",
      "  // Apply gravity to velocity\n",
      "  bird.vy += bird.gravity;\n",
      "\n",
      "  // Update bird position based on velocity\n",
      "  bird.y += bird.vy;\n",
      "}\n",
      "\n",
      "// Make the bird jump\n",
      "function jump() {\n",
      "  bird.vy = -bird.jumpVelocity; // set initial jump velocity\n",
      "}\n",
      "\n",
      "// Main game loop\n",
      "function gameLoop() {\n",
      "  updateBird();\n",
      "  // Render the bird at its new position\n",
      "  // ...\n",
      "}\n",
      "\n",
      "// Handle user input (e.g., jump button press)\n",
      "function handleInput() {\n",
      "  if (jumpButtonPressed) {\n",
      "    jump();\n",
      "  }\n",
      "}\n",
      "```\n",
      "Note that this is a highly simplified example and may not be exactly how the Flappy Bird game implements jumping and gravity. However, it should give you a general idea of how these features can be implemented using basic physics and velocity updates.\n",
      "\n",
      "In the context of the provided code snippets, the actual implementation of jumping and gravity may be hidden within the `src/main.js` file, which is not included in the provided code. You would need to examine the code in `main.js` to see how the jumping and gravity mechanisms are implemented.\n"
     ]
    }
   ],
   "source": [
    "clone_and_read(\"https://github.com/itsmejul/flappy-evolve\", \"How is the jumping of the birds and the gravity implemented?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ask-my-repo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
